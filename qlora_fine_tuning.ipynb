{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "! pip install datasets prettyprint evaluate rouge_score bitsandbytes peft trl transformers torch pandas numpy\n",
    "! pip install -U transformers"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JeOGWQid1Yr",
    "outputId": "de6903f4-4df4-4640-f221-78de026f59f2"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting prettyprint\n",
      "  Downloading prettyprint-0.1.5.tar.gz (2.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
      "Collecting trl\n",
      "  Downloading trl-0.16.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.5.2)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.16.1-py3-none-any.whl (336 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: prettyprint, rouge_score\n",
      "  Building wheel for prettyprint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for prettyprint: filename=prettyprint-0.1.5-py3-none-any.whl size=3027 sha256=61473b69a42b214e4537e3fff4181176711244d6b9e8d1524acaa18eb3b71462\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/98/c7/c418dff5bb3004cac4ca78b0b55141ea7cf9b428b613226970\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=a1ca049ef07c72d4e2a064d8d5e9967b4718b878767abf56f156244dd98f55da\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built prettyprint rouge_score\n",
      "Installing collected packages: prettyprint, xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, rouge_score, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, evaluate, bitsandbytes, trl\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bitsandbytes-0.45.5 datasets-3.5.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.12.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 prettyprint-0.1.5 rouge_score-0.1.2 trl-0.16.1 xxhash-3.5.0\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.51.1\n",
      "    Uninstalling transformers-4.51.1:\n",
      "      Successfully uninstalled transformers-4.51.1\n",
      "Successfully installed transformers-4.51.3\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "gwLXgGmsTgzo"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch  # PyTorch library for deep learning computations.\n",
    "# Import tokenizer and model from transformers for Natural Language Processing tasks.\n",
    "from datasets import Dataset, DatasetDict, load_dataset, interleave_datasets # Used for loading and managing datasets.\n",
    "from transformers import  (T5ForConditionalGeneration,\n",
    "                           BitsAndBytesConfig,\n",
    "                           T5Tokenizer,\n",
    "                           AutoModelForSeq2SeqLM,\n",
    "                           TrainingArguments,\n",
    "                           Trainer,\n",
    "                           AutoTokenizer,\n",
    "                           GenerationConfig)  # Components for model training and generation.\n",
    "import time\n",
    "import evaluate # Used for model evaluation metrics.\n",
    "import pandas as pd # Used for data manipulation and analysis.\n",
    "import numpy as np # Used for numerical computations.\n",
    "from peft import  LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training # Used for parameter-efficient fine-tuning.\n",
    "from trl import SFTTrainer # Used for supervised fine-tuning.\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import warnings # Used for managing warning messages.\n",
    "warnings.filterwarnings(\"ignore\") # Ignore warning messages during execution.\n",
    "\n",
    "# Check if a CUDA-enabled GPU is available, otherwise use CPU for computations.\n",
    "device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "MODEL=\"t5-3b\""
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the pre-trained tokenizer for the \"t5-small\" model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ],
   "metadata": {
    "id": "5uRUCVz-2pcL"
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Load the pre-trained \"t5-small\" model and move it to the selected device\n",
    "pre_train_model = AutoModelForSeq2SeqLM.from_pretrained(MODEL).to(device)\n",
    "\n",
    "# Iterate through a list of English prompts\n",
    "for prompt in [\"Hello, How are you?\", \"My name is Midhun\"]:\n",
    "    # Print the current input prompt\n",
    "    print(\"Input:\", prompt)\n",
    "\n",
    "    # Tokenize the input prompt and add translation instructions\n",
    "    # Return PyTorch tensors and move them to the selected device\n",
    "    inputTokens = tokenizer(\"translate English to French: {}\".format(prompt), return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate the French translation using the model\n",
    "    # Limit the output to a maximum of 50 tokens\n",
    "    outputs = pre_train_model.generate(inputTokens['input_ids'], attention_mask=inputTokens['attention_mask'], max_new_tokens=50)\n",
    "\n",
    "    # Decode the generated output tokens into readable text and print the translation\n",
    "    # Skip special tokens (like start and end tokens) in the output\n",
    "    print(\"Output:\", tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UdqVm7PUe_A6",
    "outputId": "1a9b3164-4d1e-4cb6-8e52-aafd6b357808"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input: Hello, How are you?\n",
      "Output: Bonjour, Comment allez-vous?\n",
      "Input: My name is Midhun\n",
      "Output: Mon nom est Midhun\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Check memory footprint\n",
    "if device == 'cuda':\n",
    "    print(f\"Model Memory Footprint: {pre_train_model.get_memory_footprint() / (1024 ** 3):.2f} GB\")\n",
    "else:\n",
    "    print(\"Model is loaded on CPU, memory footprint is not available.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPm6_YUMzZYB",
    "outputId": "dd745b7e-a3af-4159-feaa-e05c2c2a558b"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model Memory Footprint: 10.62 GB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "dataset_scc_train = load_dataset(\"b-mc2/sql-create-context\", split='train[:80%]')\n",
    "dataset_scc_test  = load_dataset(\"b-mc2/sql-create-context\", split='train[-20%:-10%]')\n",
    "dataset_scc_val   = load_dataset(\"b-mc2/sql-create-context\", split='train[-10%:]')\n",
    "\n",
    "dataset = DatasetDict({ 'train': interleave_datasets([dataset_scc_train]),\n",
    "                            'test': interleave_datasets([dataset_scc_test]),\n",
    "                            'validation': interleave_datasets([dataset_scc_val])})"
   ],
   "metadata": {
    "id": "lFKeP1B9frOI",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "ef7cf905c7744c7b8ab34e3ba01131ba",
      "e98bfa109ce34e18b63ba29a65f415d6",
      "6e5efb8be3db493b86ecafbf18c5f42d",
      "8ec4accc6d3a4b7d898f04619009273c",
      "542c8c847e914c75893459b462a0df53",
      "27844d753d1f40178e7ff10af50e8c43",
      "9f14c627fa8e4ae3862c6b79ecdc0bc5",
      "0079ef333b404ce6a169a118f6504423",
      "d9ddc0acdd8246f2acda987e99987b87",
      "486cd29bb13a409aacebf75755dbc66d",
      "2abe6c65b88e49e1ac8b8a0761e0df41",
      "6aeb260c4f6d4599902f3fcdff2a832d",
      "444fa0846b734b66afe4aca5504907f6",
      "eea8e9703d664fe5abbef37ae071c3b5",
      "450030d7f813448cb84a9b618e206d02",
      "6a84d43bc90142ffbe24ec3630b0fb97",
      "fc0ad6f469134982b913ca2932f7590d",
      "d98943d4f06d4102891d503184555866",
      "968ebc358e7b4d0a839b17c29cac451d",
      "b5de976aaced46b89444f5fa22dc9aea",
      "8f427250eedd4a4897e43b2f6a3fe1d2",
      "28ad54f92a6944a49500447721884c67",
      "6b5c27c301004b2fa9739773adb98361",
      "edb17d3bdea24407bb82c788ba81b58e",
      "404cad8c83274c2ca966340df98e6fea",
      "2ca044e195704f7288be9d2a86ecef14",
      "38ec71837a09404f8139a22239bd0fc2",
      "851deece9cfa44b7bdba58b5ad8f4717",
      "2b2da36c3c18439280a19ba88a9c6e8c",
      "232acb13ef2548c097746ae4585a2ad6",
      "ec640f009ba14a98a2ff10ecd69e070d",
      "771f8646116340acb07186c0b1ded122",
      "588a9f1ae1c24b12b3b3b65866db87e3"
     ]
    },
    "outputId": "19dc3d96-80f8-4c48-d336-bf47439f203f"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/4.43k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef7cf905c7744c7b8ab34e3ba01131ba"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "sql_create_context_v4.json:   0%|          | 0.00/21.8M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6aeb260c4f6d4599902f3fcdff2a832d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/78577 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b5c27c301004b2fa9739773adb98361"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "print(\"-----Train Dataset----\")\n",
    "pprint(dataset['train'][0])\n",
    "print(\"-----Test Dataset-----\")\n",
    "pprint(dataset['test'][0])\n",
    "print(\"----Test Dataset:-----\")\n",
    "pprint(dataset['validation'][0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F7KgLc0ggEv_",
    "outputId": "6e755999-58fe-4d96-97a1-e9e4472082f3"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-----Train Dataset----\n",
      "{'answer': 'SELECT COUNT(*) FROM head WHERE age > 56',\n",
      " 'context': 'CREATE TABLE head (age INTEGER)',\n",
      " 'question': 'How many heads of the departments are older than 56 ?'}\n",
      "-----Test Dataset-----\n",
      "{'answer': 'SELECT date FROM table_name_11 WHERE away_team = \"essendon\"',\n",
      " 'context': 'CREATE TABLE table_name_11 (date VARCHAR, away_team VARCHAR)',\n",
      " 'question': 'On what Date did the Away team essendon play?'}\n",
      "----Test Dataset:-----\n",
      "{'answer': 'SELECT home_team FROM table_name_80 WHERE away_team = \"lincoln '\n",
      "           'city\"',\n",
      " 'context': 'CREATE TABLE table_name_80 (home_team VARCHAR, away_team VARCHAR)',\n",
      " 'question': 'What is the Home team at the Lincoln City Away game?'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def tokenize_function(example):\n",
    "    \"\"\"\n",
    "    Tokenizes the input example and prepares it for the model.\n",
    "\n",
    "    This function takes an example from the dataset, combines the context and\n",
    "    question into a prompt, tokenizes the prompt and answer using the\n",
    "    pre-trained tokenizer, and returns the example with added 'input_ids'\n",
    "    and 'labels'.\n",
    "\n",
    "    Args:\n",
    "        example (dict): A dictionary containing 'context', 'question', and 'answer'.\n",
    "\n",
    "    Returns:\n",
    "        dict: The modified example with added 'input_ids' and 'labels'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define special tokens to mark different sections of the input\n",
    "    _context = \"Tables:\\n\"\n",
    "    _question = \"\\n\\nQuestion:\\n\"\n",
    "    _answer = \"\\n\\nAnswer:\\n\"\n",
    "\n",
    "    # Combine context and question into a prompt\n",
    "    # Create the prompt string with special tokens\n",
    "    prompt = [_context + context + _question + question + _answer for context, question in zip(example['context'], example['question'])]\n",
    "\n",
    "    # Tokenize the prompt and store as 'input_ids'\n",
    "    # Add padding='max_length' to ensure all sequences have the same length\n",
    "    # Use padding=True and truncation=True to handle varying sequence lengths\n",
    "    # and ensure consistency in tensor shapes.\n",
    "    example['input_ids'] = tokenizer(prompt, padding='max_length',max_length=512, truncation=True, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    # Tokenize the answer and store as 'labels'\n",
    "    # Add padding='max_length' to ensure all sequences have the same length\n",
    "    # Use padding=True and truncation=True to handle varying sequence lengths\n",
    "    # and ensure consistency in tensor shapes.\n",
    "    example['labels'] = tokenizer(example['answer'], padding='max_length',max_length=200, truncation=True, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    return example\n",
    "\n",
    "\n",
    "# Apply the tokenize_function to the dataset\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "# Remove original text columns, as they are now represented by 'input_ids' and 'labels'\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['question', 'context', 'answer'])\n",
    "print(\"Tokenized Dataset\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131,
     "referenced_widgets": [
      "4f89214c33b848dbb3cfe38f26cde950",
      "cd19e1690935437a8ac083743f8d0dbc",
      "6893f13e7ed74d34a53ae1e72e246471",
      "42a31fd7863847278df4580457460b6f",
      "7586415c4aea4f4fbdf4cdd9cf0b0338",
      "30018a5015cd4e888b704e68512342dc",
      "451a7d3d75d44f2cb0843a45cf4f79e5",
      "0071953bfa1d4eefa976b38c6df13c4a",
      "4b6915901728489388c51284967bdf93",
      "105eeb7b20b14e22a0ffecbc1e7d26a3",
      "3f1bd32975244a6da4dcfcd1e81818d7",
      "c2af58b44c9e49a18a4cea8c60c20ef9",
      "0a47ef0c2ff84aaf9f45c3042824039b",
      "49d6ae90dc4340388e42ea42e27db8ca",
      "76cc1575b06c478589cdc5d0c1c7c9b9",
      "e87522f1317e428cadb0bff18dd027b1",
      "2072ae37760645b587bde936cf46b8f0",
      "df51a22e845746bea1251f92ba65cbf0",
      "a3f5712ee7fd4d42aff264a202d184ea",
      "8bf0937330f248ac9d9a6c17f4dcbf19",
      "949c693d57e24edfa8d82df166d4b3c9",
      "5968e44ea43342f79a8e241239dc7dbb",
      "ae296d126ce34f79b10670130aecef54",
      "b00fb48063214b92a688a8274c1768b2",
      "6464812fed394a6fabcbb12db3cbd98f",
      "2b64ed317e7548ce8fcb45d8052a0a8b",
      "399c3b4c4ac542deba6e3cdf06cfddd7",
      "3f8fdd9803f641a8a3191afeda92ba3d",
      "e8c5143f580445cc96d8bf295608fe25",
      "1816750486ee4a99ad885f5707833dce",
      "f2348bda00e04387ac23bdd82259ff52",
      "fb28f4209b404cee9311b4153f67cc8b",
      "e4f2899ac22b468792d2e089c6e904c8"
     ]
    },
    "id": "A_UA9Hg4gEjd",
    "outputId": "4c966a7d-c7ad-40b8-db93-0370611b27e9"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/62862 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f89214c33b848dbb3cfe38f26cde950"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/7857 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2af58b44c9e49a18a4cea8c60c20ef9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/7858 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae296d126ce34f79b10670130aecef54"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tokenized Dataset\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pprint(tokenized_datasets.keys())\n",
    "pprint(tokenized_datasets['train'][0].keys())\n",
    "pprint(tokenized_datasets['train'][0]['input_ids'][:10])\n",
    "pprint(tokenized_datasets['train'][0]['labels'][:10])\n",
    "pprint(tokenized_datasets)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ptcge8FQgL5G",
    "outputId": "786a5208-714c-44ac-d270-92a915eed4ff"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['train', 'test', 'validation'])\n",
      "dict_keys(['input_ids', 'labels'])\n",
      "[4398, 7, 10, 205, 4386, 6048, 332, 17098, 819, 41]\n",
      "[3, 23143, 14196, 2847, 17161, 599, 1935, 61, 21680, 819]\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 62862\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 7857\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 7858\n",
      "    })\n",
      "})\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "index = 555  # Set the index to 555 to select the first example from the dataset\n",
    "\n",
    "# Get the question, context, and answer from the 'test' split of the dataset\n",
    "question = dataset['test'][index]['question']\n",
    "context = dataset['test'][index]['context']\n",
    "answer = dataset['test'][index]['answer']\n",
    "\n",
    "# Create the prompt by formatting the context and question\n",
    "prompt = f\"\"\"Tables:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the prompt and convert it to PyTorch tensors\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "# Move the input tensors to the 'cuda' device (GPU) if available\n",
    "inputs = inputs.to('cuda')\n",
    "\n",
    "# Generate the answer using the pre-trained model\n",
    "output = tokenizer.decode(\n",
    "    pre_train_model.generate(\n",
    "        inputs[\"input_ids\"],  # Pass the tokenized input to the model\n",
    "        max_new_tokens=25,  # Limit the output to a maximum of 200 tokens\n",
    "    )[0],  # Get the first element of the generated output\n",
    "    skip_special_tokens=True  # Remove special tokens from the output\n",
    ")\n",
    "\n",
    "# Create a dashed line for visual separation in the output\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "# Print the prompt, actual answer, and the model's generated answer\n",
    "print(dash_line)\n",
    "print(f'Prompt:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'Actual answer:\\n{answer}\\n')\n",
    "print(dash_line)\n",
    "pprint(f'Pre-trained Model Answer - Zero Zhot:\\n\\n{output}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7xS8HmR8gQK-",
    "outputId": "90051196-ae2a-4241-f4ae-846135f96fa1"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "Prompt:\n",
      "Tables:\n",
      "CREATE TABLE table_name_33 (d_41 VARCHAR, r_51 VARCHAR)\n",
      "\n",
      "Question:\n",
      "Tell me the D 41 and R 51 of r 11\n",
      "\n",
      "Answer:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Actual answer:\n",
      "SELECT d_41 FROM table_name_33 WHERE r_51 = \"r 11\"\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "'Pre-trained Model Answer - Zero Zhot:\\n\\nD 41 and R 51 of r 11'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# unloding the model from memory\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "id": "IS6IZmd90EyJ"
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Get the data type for float16 from the PyTorch library.\n",
    "# This will be used for computations during quantization.\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "# Create a BitsAndBytesConfig object to configure quantization settings.\n",
    "# This is used to optimize the model's memory footprint and inference speed.\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  # Load the model weights in 4-bit precision.\n",
    "        bnb_4bit_quant_type=\"nf4\",  # Use the NF4 quantization type for 4-bit weights.\n",
    "        bnb_4bit_compute_dtype=compute_dtype,  # Use float16 for computations during quantization.\n",
    "        bnb_4bit_use_double_quant=True,  # Enable double quantization for further optimization.\n",
    ")"
   ],
   "metadata": {
    "id": "gk8BKEmEgepe"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_q = AutoModelForSeq2SeqLM.from_pretrained(MODEL,quantization_config=bnb_config).to(device)\n",
    "\n",
    "model_q.get_memory_footprint()\n",
    "pprint(model_q)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "3d24d39151d441ef833dfa8e6dbb7e5b",
      "28e2c291a93d40e4bc9161d9162ab345",
      "c4c99da3c3bb414e8e5651240c57966d",
      "1d68617e97374b0da272af7fb7597728",
      "ce4d6589cfce4a609a10eba3551bef2b",
      "558b0454c2be4793b35170ae17512190",
      "846543453c6a459fae959c97275cc110",
      "c6f04cfd4cde43bd9a154dfe9267bc29",
      "2135cfcbf3f54bcabc1fa8d7e7578cee",
      "f3c660c00627475c9882b06f321b355c",
      "1f56148bf02045a2acc8a8d4b09f90de"
     ]
    },
    "id": "zIxCvmrqgruM",
    "outputId": "50fd4bb8-c681-4c1c-a382-6bb17ad9b2c2"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/11.4G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d24d39151d441ef833dfa8e6dbb7e5b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "T5ForConditionalGeneration(\n",
      "  (shared): Embedding(32128, 1024)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 1024)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (k): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (v): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (o): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 32)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear4bit(in_features=1024, out_features=16384, bias=False)\n",
      "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-23): 23 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (k): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (v): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (o): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear4bit(in_features=1024, out_features=16384, bias=False)\n",
      "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 1024)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (k): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (v): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (o): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 32)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (k): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (v): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (o): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear4bit(in_features=1024, out_features=16384, bias=False)\n",
      "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-23): 23 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (k): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (v): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (o): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (k): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (v): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (o): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear4bit(in_features=1024, out_features=16384, bias=False)\n",
      "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Q4iUmiXaEn6M"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "2PCfAOPTfrDt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the configuration for LoRA (Low-Rank Adaptation) using LoraConfig\n",
    "peft_config = LoraConfig(\n",
    "        inference_mode=False,  # Set to False for inference_mode\n",
    "        lora_alpha=16,  # Scaling factor for the LoRA updates. Controls the impact of LoRA layers.\n",
    "        lora_dropout=0.5,  # Dropout probability for the LoRA layers, helps prevent overfitting.\n",
    "        r=16,  # Rank of the LoRA update matrices. Lower rank leads to fewer trainable parameters.\n",
    "        bias=\"none\",  # Whether to add a bias term to the LoRA layers. \"none\" means no bias is added.\n",
    "        task_type=TaskType.SEQ_2_SEQ_LM,# Specifies the task type as sequence-to-sequence language modeling.\n",
    "        target_modules=[\"q\", \"v\", \"o\"],  # Specifies the modules to which LoRA will be applied. Here, it's applied to 'q' and 'v' modules.\n",
    "        modules_to_save=[\"lm_head\"],\n",
    "        )\n"
   ],
   "metadata": {
    "id": "ddchJHyVikCb"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# from peft import get_peft_model\n",
    "\n",
    "# model = get_peft_model(model, peft_config)\n",
    "\n",
    "model_q.add_adapter(peft_config, adapter_name=\"adapter_text2sql\")\n",
    "model_q.set_adapter(\"adapter_text2sql\")\n",
    "pprint(model_q)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c75t39FEjEcO",
    "outputId": "7bac5b17-ccbe-4556-e4d4-849153ae0936"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "T5ForConditionalGeneration(\n",
      "  (shared): Embedding(32128, 1024)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 1024)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (adapter_text2sql): Dropout(p=0.5, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=1024, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (v): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (adapter_text2sql): Dropout(p=0.5, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=1024, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (adapter_text2sql): Dropout(p=0.5, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=16, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (relative_attention_bias): Embedding(32, 32)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear4bit(in_features=1024, out_features=16384, bias=False)\n",
      "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-23): 23 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (adapter_text2sql): Dropout(p=0.5, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=1024, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (v): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (adapter_text2sql): Dropout(p=0.5, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=1024, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (adapter_text2sql): Dropout(p=0.5, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=16, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear4bit(in_features=1024, out_features=16384, bias=False)\n",
      "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 1024)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (adapter_text2sql): Dropout(p=0.5, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=1024, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (v): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (adapter_text2sql): Dropout(p=0.5, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=1024, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (adapter_text2sql): Dropout(p=0.5, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=16, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (relative_attention_bias): Embedding(32, 32)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (adapter_text2sql): Dropout(p=0.5, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=1024, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (v): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (adapter_text2sql): Dropout(p=0.5, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=1024, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (adapter_text2sql): Dropout(p=0.5, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=16, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear4bit(in_features=1024, out_features=16384, bias=False)\n",
      "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-23): 23 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (adapter_text2sql): Dropout(p=0.5, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=1024, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (v): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (adapter_text2sql): Dropout(p=0.5, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=1024, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (adapter_text2sql): Dropout(p=0.5, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=16, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (adapter_text2sql): Dropout(p=0.5, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=1024, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "              (v): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1024, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (adapter_text2sql): Dropout(p=0.5, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=1024, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (adapter_text2sql): Dropout(p=0.5, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (adapter_text2sql): Linear(in_features=16, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear4bit(in_features=1024, out_features=16384, bias=False)\n",
      "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): ModulesToSaveWrapper(\n",
      "    (original_module): Linear(in_features=1024, out_features=32128, bias=False)\n",
      "    (modules_to_save): ModuleDict(\n",
      "      (adapter_text2sql): Linear(in_features=1024, out_features=32128, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Check memory footprint\n",
    "if device == 'cuda':\n",
    "    print(f\"Model Memory Footprint: {model_q.get_memory_footprint() / (1024 ** 3):.2f} GB\")\n",
    "else:\n",
    "    print(\"Model is loaded on CPU, memory footprint is not available.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xk5yzEKS5z2R",
    "outputId": "924fa286-e2c7-438d-f69f-0464b2a31a9b"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model Memory Footprint: 4.13 GB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = model.num_parameters()\n",
    "    for _, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "print_trainable_parameters(model_q)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfDjTNFQZh3L",
    "outputId": "87fcd7ba-bb91-4a7a-a00f-1af2aab87688"
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "trainable params: 50593792 || all params: 2902192128 || trainable%: 1.7432957491641297\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Set the directory to save the fine-tuned model and its checkpoints\n",
    "output_dir = f'./peft_fine_tuning_text2sql-{str(int(time.time()))}'\n",
    "\n",
    "# Define training arguments using the TrainingArguments class\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,  # Directory to save model checkpoints\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=5000,\n",
    "    optim=\"paged_adamw_8bit\",  #used with QLoRA\n",
    "    per_device_train_batch_size=6,\n",
    "    per_device_eval_batch_size=6,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=0.5,\n",
    "    report_to='none',  # Disable reporting to Weights & Biases (wandb.ai)\n",
    ")\n",
    "\n",
    "# Create a Trainer instance to manage the fine-tuning process\n",
    "trainer = Trainer(\n",
    "    model=model_q,  # The model to fine-tune\n",
    "    args=training_args,  # Training arguments\n",
    "    train_dataset=tokenized_datasets['train'],  # Training dataset\n",
    "    eval_dataset=tokenized_datasets['validation'],  # Evaluation dataset\n",
    ")\n",
    "\n",
    "# Start the fine-tuning process\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model to a directory\n",
    "model_q.save_pretrained(\"model_q_text2sql\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DSw4XS0Jje9p",
    "outputId": "daaf107c-a9e0-40a0-d5b2-5b07150f20ad"
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "error",
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 896.00 KiB is free. Process 11642 has 39.54 GiB memory in use. Of the allocated memory 38.67 GiB is allocated by PyTorch, and 367.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ae91551c1b56>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Start the fine-tuning process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Save the fine-tuned model to a directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2246\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2558\u001b[0m                     )\n\u001b[1;32m   2559\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2560\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2562\u001b[0m                     if (\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3735\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3736\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3799\u001b[0m                 \u001b[0mloss_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloss_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3801\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3802\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoder_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1867\u001b[0m             \u001b[0;31m# Convert encoder inputs in embeddings if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1868\u001b[0;31m             encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1869\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1870\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 )\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1132\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0mcache_position\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m     ):\n\u001b[0;32m--> 682\u001b[0;31m         self_attention_outputs = self.layer[0](\n\u001b[0m\u001b[1;32m    683\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    598\u001b[0m     ):\n\u001b[1;32m    599\u001b[0m         \u001b[0mnormed_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         attention_output = self.SelfAttention(\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0mnormed_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0mis_cross_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_value_states\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mquery_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[0mquery_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_value_proj_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m                 \u001b[0;31m# newer PyTorch versions but this would need extensive testing to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m                 \u001b[0;31m# sure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mactive_adapter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_adapters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 896.00 KiB is free. Process 11642 has 39.54 GiB memory in use. Of the allocated memory 38.67 GiB is allocated by PyTorch, and 367.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "fine_tuned_model = AutoModelForSeq2SeqLM.from_pretrained(\"model_q_text2sql\")\n",
    "fine_tuned_model = fine_tuned_model.to('cuda')"
   ],
   "metadata": {
    "id": "Ab-phVA7n8Zr"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "index = 555  # Set the index to 555 to select the first example from the dataset\n",
    "\n",
    "# Get the question, context, and answer from the 'test' split of the dataset\n",
    "question = dataset['test'][index]['question']\n",
    "context = dataset['test'][index]['context']\n",
    "answer = dataset['test'][index]['answer']\n",
    "\n",
    "# Create the prompt by formatting the context and question\n",
    "prompt = f\"\"\"Tables:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the prompt and convert it to PyTorch tensors\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "# Move the input tensors to the 'cuda' device (GPU) if available\n",
    "inputs = inputs.to('cuda')\n",
    "\n",
    "# Generate the answer using the pre-trained model\n",
    "output = tokenizer.decode(\n",
    "    fine_tuned_model.generate(\n",
    "        inputs[\"input_ids\"],  # Pass the tokenized input to the model\n",
    "        max_new_tokens=200,  # Limit the output to a maximum of 25 tokens\n",
    "    )[0],  # Get the first element of the generated output\n",
    "    skip_special_tokens= True #Remove special tokens from the output\n",
    ")\n",
    "\n",
    "# Create a dashed line for visual separation in the output\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "# Print the prompt, actual answer, and the model's generated answer\n",
    "print(dash_line)\n",
    "print(f'Prompt:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'Actual answer:\\n{answer}\\n')\n",
    "print(dash_line)\n",
    "pprint(f'fine_tuned_model Answer - Zero Zhot:\\n\\n{output}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ueMLokK_oF9-",
    "outputId": "985fed23-4a1c-4769-ef7d-02808bfc7f9d"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "Prompt:\n",
      "Tables:\n",
      "CREATE TABLE table_name_33 (d_41 VARCHAR, r_51 VARCHAR)\n",
      "\n",
      "Question:\n",
      "Tell me the D 41 and R 51 of r 11\n",
      "\n",
      "Answer:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Actual answer:\n",
      "SELECT d_41 FROM table_name_33 WHERE r_51 = \"r 11\"\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "'fine_tuned_model Answer - Zero Zhot:\\n\\nD 41 and R 51 of r 11'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Iterate through a list of English prompts\n",
    "for prompt in [\"Hello, How are you?\", \"My name is Midhun\"]:\n",
    "    # Print the current input prompt\n",
    "    print(\"Input:\", prompt)\n",
    "\n",
    "    # Tokenize the input prompt and add translation instructions\n",
    "    # Return PyTorch tensors and move them to the selected device\n",
    "    inputTokens = tokenizer(\"translate English to French: {}\".format(prompt), return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate the French translation using the model\n",
    "    # Limit the output to a maximum of 50 tokens\n",
    "    outputs = fine_tuned_model.generate(inputTokens['input_ids'], attention_mask=inputTokens['attention_mask'], max_new_tokens=50)\n",
    "\n",
    "    # Decode the generated output tokens into readable text and print the translation\n",
    "    # Skip special tokens (like start and end tokens) in the output\n",
    "    print(\"Output:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ],
   "metadata": {
    "id": "uQqbVSjaoONa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a612e1d8-71e7-4345-b7a1-188ae0ee0a91"
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input: Hello, How are you?\n",
      "Output: Bonjour, Comment allez-vous?\n",
      "Input: My name is Midhun\n",
      "Output: Mon nom est Midhun\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! cp -r /content/drive/MyDrive/LLM_fine_tuning/model_q_text2sql /content/"
   ],
   "metadata": {
    "id": "S7wWZwqaWA5Q"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate the Model Quantitatively (with ROUGE Metric)"
   ],
   "metadata": {
    "id": "1dOLiQCGWKoy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Perform inferences for test dataset. Do 25 only, due to time it takes.\n",
    "\n",
    "questions = dataset['test'][0:25]['question']\n",
    "contexts = dataset['test'][0:25]['context']\n",
    "human_baseline_answers = dataset['test'][0:25]['answer']\n",
    "\n",
    "original_model_answers = []\n",
    "finetuned_model_answers = []\n",
    "\n",
    "for idx, question in enumerate(questions):\n",
    "\n",
    "    prompt = f\"\"\"Tables:\n",
    "{contexts[idx]}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "    input_ids = input_ids.to('cuda')\n",
    "\n",
    "    human_baseline_text_output = human_baseline_answers[idx]\n",
    "\n",
    "    original_model_outputs = pre_train_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=300))\n",
    "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "    original_model_answers.append(original_model_text_output)\n",
    "\n",
    "    finetuned_model_outputs = fine_tuned_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=300))\n",
    "    finetuned_model_text_output = tokenizer.decode(finetuned_model_outputs[0], skip_special_tokens=True)\n",
    "    finetuned_model_answers.append(finetuned_model_text_output)\n",
    "\n",
    "zipped_summaries = list(zip(human_baseline_answers, original_model_answers, finetuned_model_answers))\n",
    "\n",
    "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_answers', 'original_model_answers', 'finetuned_model_answers'])\n",
    "\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "original_model_results = rouge.compute(\n",
    "    predictions=original_model_answers,\n",
    "    references=human_baseline_answers[0:len(original_model_answers)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results)\n",
    "\n",
    "\n",
    "finetuned_model_results = rouge.compute(\n",
    "    predictions=finetuned_model_answers,\n",
    "    references=human_baseline_answers[0:len(finetuned_model_answers)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "print('FINE-TUNED MODEL:')\n",
    "print(finetuned_model_results)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158,
     "referenced_widgets": [
      "a90dad490bd24cc6b3a0082b0b1b1af1",
      "33cf68c755c745e684915137201c99f5",
      "37763152bad5465e97a886078010b6d9",
      "012eb7bc63b84d71951e1502439f19b7",
      "2b44c6eb804d4c03b66a1d8d923ea292",
      "ffc9a23e9ea640f084ea71700a29bf86",
      "7710552d06c44d869a3b23de45ddcdf6",
      "85db4280e8fb4211831ba4ad94a14eaf",
      "e708690c59c342d3a0f0f767917f0716",
      "77fe876a9230481d8bf306ffc5c1dcf3",
      "4dece7cdcf6d42d99b674fbc330bbf2c"
     ]
    },
    "id": "FVOpGuBOa4cq",
    "outputId": "c9be1183-899f-4515-ddba-6ae661284189"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`generation_config` default values have been modified to match model-specific defaults: {'pad_token_id': 0, 'eos_token_id': 1, 'decoder_start_token_id': 0}. If this is not desired, please set these values explicitly.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a90dad490bd24cc6b3a0082b0b1b1af1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ORIGINAL MODEL:\n",
      "{'rouge1': np.float64(0.36909067729655964), 'rouge2': np.float64(0.2108754578754579), 'rougeL': np.float64(0.33789630739630744), 'rougeLsum': np.float64(0.33828134175193)}\n",
      "FINE-TUNED MODEL:\n",
      "{'rouge1': np.float64(0.36340115096461834), 'rouge2': np.float64(0.19589221889221892), 'rougeL': np.float64(0.3535362576879605), 'rougeLsum': np.float64(0.3565740336375012)}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "![image.png](data:image/png;base64,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)\n",
    "\n",
    "\n",
    "ROUGE-L and ROUGE-Lsum: These metrics consider the longest common subsequence (LCS) between the generated and reference texts, which gives a better indication of overall sentence similarity. Here, the fine-tuned model has noticeably higher ROUGE-L and ROUGE-Lsum scores compared to the original model. This suggests that the fine-tuned model might have generated text that is more semantically similar to the reference text, even if it doesn't have as much word-for-word overlap.\n",
    "\n"
   ],
   "metadata": {
    "id": "_enlkAUvdVyc"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "0i91mVFsdi7a"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}